/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /workspace/diffusion-llms/models/regressor_mlp/checkpoints exists and is not empty.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loading `train_dataloader` to estimate number of stepping batches.
/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=223` in the `DataLoader` to improve performance.

  | Name     | Type           | Params | Mode
----------------------------------------------------
0 | backbone | LladaBackbone  | 8.0 B  | train
1 | model    | LLaDaRegressor | 8.4 M  | train
----------------------------------------------------
526 M     Trainable params
7.5 B     Non-trainable params
8.0 B     Total params
32,095.896Total estimated model params size (MB)
6         Modules in train mode
422       Modules in eval mode
Epoch 0:   9%| | 72/847 [01:28<15:51,  0.81it/s, v_num=wgon, train/loss_log_MSE=10.30, train/RMSE_tokens_step=5.03e+3, train/MAE_tokens_step=3.48e+3, train/R2_
/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=223` in the `DataLoader` to improve performance.

Detected KeyboardInterrupt, attempting graceful shutdown ...
